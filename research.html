<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>J. Arturo Cocoma-Ortega, PhD Student</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<link href="main.css" rel="stylesheet" type="text/css" />
 <!-- Add icon library -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
</head>
<body>
<div class="header">
  <div class="logo">
    <h1>J. Arturo Cocoma-Ortega, PhD</h1>
  </div>
  <div class="navigation">
    <ul>
      <li><a href="index.html">Home</a> </li>
      <li><a href="#"><b>Research</b></a> </li>
      <li><a href="publications.html">Publications</a> </li>
      <li><a href="awards.html">Awards</a> </li>
      <li><a href="contact.html">Contact</a> </li>
    </ul>
  </div>
</div>
<div class="main">
  <div class="left-column">
    <h1>Deep learning for high-frequency camera pose estimation</h1>
    <br>
    <h2>A Compact CNN apporach for Drone Localisation in Autonomous Drone Racing</h2>
    <p>In autonomous drone racing, a drone flies through a gate track at high speed. Some solutions involve the use of camera localisation to control the drone. However, effective localisation is very demanding in processing time, which may compromise the flight speed. To address the latter, we propose a deep learning-based method for camera localisation that processes a small sequence of images of the scene at high-frequency operation. Our solution is a compact convolutional neural network based on the Inception network that uses a sequence of grey-scale images rather than colour images as input; we have called this network ‘GreySeqNet’. Our approach aims at leveraging the localisation process by using a small stack of consecutive images fed as input to the network. To save computational effort, we explorethe use of grey images instead of colour images, thus saving convolutional layers. We have conducted experiments in a simulated environment to measure the performance of GreySeqNet in different race tracks with variations in gate’s height and position. According to the results obtained in several test runs, our method achieves a camera pose estimation at an average operation frequency of 83 Hz running on GPU and 26 Hz on CPU, with an average camera pose error of 31 cm.
    </p>
    <iframe width="480" height="315" src="https://www.youtube.com/embed/aDlBEtox4vY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

    <h2>Overcoming the Blind Spot in CNN-based Gate Detection for Autonomous Drone Racing</h2>
    <p>In this work, we present a methodology for autonomous navigation in the context of Autonomous Drone Racing. Using visual information it has a blind spot when the camera is near to the object.  We propose based on CNN gate detect a stochastic algorithm for distance estimation that overcomes the blind spot during autonomous navigation.
    </p>
    <iframe width="480" height="315" src="https://www.youtube.com/embed/OBAxb-iFMX0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

    <h2>Towards High-Speed Localisation for Autonomous Drone Racing</h2>
    <p>In this video, We show our proposed algorithm designed to autonomous Drone flight in the context of Autonomous Drone Racing. Our proposed algorithm is based on CNN to predict the drone's pose. Our algorithm takes the pose and commands the drone to centre to the gate and then cross it. The first part of the video shows the results testing drone's pose prediction vs groundtruth. The second part demonstrated an autonomous flight to cross three gates in a real environment race track. Our proposed CNN can estimates the drones pose at high speed up to 100 Hz.</p>

    <iframe width="480" height="315" src="https://www.youtube.com/embed/C7goGTZ4F0k" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    <h2>A CNN-based Drone Localisation Approach for Autonomous Drone Racing</h2>
    <p>To fly through a gate in the ADR context, it would be important to know the position of the drone related to the gate in order to design a flight trajectory that can cross the gate. In this video, we show our proposed algorithm based on CNN to predict the Drone's pose and based on this pose our algorithm commands the Drone to cross the gate. At begin, it is shown the prediction vs the ground truth in 2D and 3D view, finally, we present our algorithm in action, it crosses three gates autonomously in a simulated environment.</p>

    <iframe width="480" height="315" src="https://www.youtube.com/embed/5rboqinFXYo" title="A CNN based Drone localisation Approach" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    <br>
    <br></br>
    <h1>Real-time system for Rodent detection and behavioural classification</h2>
    <br>
    <h2>A Deep Learning-based Approach For Real-time Rodent Detection and Behaviour Classification</h2>
    <p>Animal models are helpful to evaluate the effects of some drugs in the treatment of brain diseases, such as the case of the Open Field Maze. Usually, these tests are recorded in video and analysed afterwards to carry out manual annotations about the activity and behaviour of the rat. Usually, these videos must be watched repeatedly to ensure correct annotations, but they are prone to become a tedious task and are highly likely to produce human errors. Existing commercial systems for automatic detection of the rat and classification of its behaviours may become inaccessible for research teams that cannot afford the license cost. Motivated by the latter, we propose a methodology for simultaneous rat detection and behaviour classification using inexpensive hardware in this work. Our proposal is a Deep Learning-based two-step methodology to simultaneously detect the rat in the test and classify its behaviour. In the first step, a single shot detector network is used to detect the rat; then, the systems crop the image using the bounding box to generate a sequence of six images that input our BehavioursNet network to classify the rodent’s behaviour. Finally, based on the results of these steps, the system generates an ethogram for the complete video, a trajectory plot, a heatmap plot for most visited regions and a video showing the rat’s detection and its behaviours. Our results show that it is possible to perform these tasks at a processing rate of 23 Hz, with a low error of 6 pixels in the detection and a first approach to classify ambiguous behaviours such as resting and grooming, with an average precision of 60%, which is competitive with that reported in the literature.</p>

    <iframe width="480" height="315" src="https://www.youtube.com/embed/wTie0FvzjGI" title="A deep learning-based approach for real-time rodent detection and behaviour classification" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    <h2>Towards a Rodent Tracking and Behaviour Detection System in Real Time</h2>
    <p>To analyze rodent behaviors in non-conditioned animal models is an important task that enables a researcher to elaborated conclusions about the effects in the behavior after drug application. Because the amount of data generated in the use of this kind of test, an automatized system that can record these behaviors becomes relevant. There are several proposals aiming at identifying and tracking the rodent in the open field maze, however, behavior identification is a highly desirable feature that is not included. Other works can identify behaviors, but due to high computational costs, special computers or devices are required. In this work, we propose an automatic system based on features computed by a stochastic filter that allows the development of rules to detect specific behaviors exhibited in the open field maze. We demonstrate that it is possible to track a rodent and identify behaviors in real-time (30 fps) and also in high speed (>100Hz) without the need of powerful devices or special conditions for the environment.</p>
    <iframe width="480" height="315" src="https://www.youtube.com/embed/6Smkff19r14" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


  </div>
  
  <div class="right-column">
    <h3>Follow my social and academic networks:</h3>

   

	<!-- Add font awesome icons -->
	<a href="https://scholar.google.com/citations?hl=es&user=l8nneEgAAAAJ" class="ai ai-google-scholar-square ai-5x"></a>

	<a href="https://www.researchgate.net/profile/Jose-Cocoma-Ortega" class="ai ai-researchgate-square ai-5x"></a>

	<a href="https://publons.com/researcher/ABF-4298-2021/" class="ai ai-publons-square ai-5x"></a>

	<a href="https://orcid.org/0000-0002-8713-7653" class="ai ai-orcid-square ai-5x"></a>

	<a href="http://www.scopus.com/inward/authorDetails.url?authorID=57194143166&partnerID=MN8TOARS" class="ai ai-scopus-square ai-5x"></a>

	

	


	<a href="https://twitter.com/arturo_cocoma" class="fa fa-twitter fa-4x"></a>
	<a href="http://www.linkedin.com/in/josé-arturo-cocoma-ortega-229bb5137" class="fa fa-linkedin fa-4x"></a>
	<a href="#" class="fa fa-instagram fa-4x"></a>
	<a href="#" class="fa fa-youtube fa-4x"></a>



    <p></p>
  
  </div>
</div>

<div id="sfcnkqrug66lllfb88cddfjkgwlhb8mnkju"></div>
<script type="text/javascript" src="https://counter9.stat.ovh/private/counter.js?c=nkqrug66lllfb88cddfjkgwlhb8mnkju&down=async" async></script>
<br><noscript><a href="https://www.contadorvisitasgratis.com" title="Contador de visitas"><img src="https://counter9.stat.ovh/private/contadorvisitasgratis.php?c=nkqrug66lllfb88cddfjkgwlhb8mnkju" border="0" title="Contador de visitas" alt="Contador de visitas"></a></noscript>

<div class="seperater">
  <!--leave tag empty!-->
</div>
<div class="footer">
  <div class="footer-inner">
    <div class="footer-left">
      <ul>
        <li>All rights reserved - </li>
        <li>J. Arturo's personal webpage - </li>
        <li>2022</li>
      </ul>
      <ul>
        <li class="small"><a href="http://www.firebubble.co.uk">web design</a> </li>
        <li class="small">by sjl <a href="http://www.sjlwebdesign.co.uk">web design </a></li>
      </ul>
    </div>
    <div class="footer-right">
      <ul>
        <li><a href="index.html">Home</a> | </li>
        <li><a href="#">Research</a> | </li>
        <li><a href="publications.html">Publications</a> | </li>
        <li><a href="awards.html">Awards</a> | </li>
        <li><a href="contact.html">Contact</a> | </li>
      </ul>
    </div>
  </div>
</div>
</body>
</html>
